{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762181a2-6187-4af4-94b0-7bcc2caf61bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ee8dd69036455c8f98465f01f301d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()  # 在 notebook 弹窗中填入你的 HF 访问令牌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b3d9c-7d36-474f-904e-d52a00f94e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, gc\n",
    "from torch import autocast\n",
    "from diffusers import DiffusionPipeline, StableDiffusion3Pipeline, BitsAndBytesConfig, DDPMScheduler\n",
    "from transformers import CLIPTextModel, CLIPTokenizer, T5TokenizerFast\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipe = StableDiffusion3Pipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-3.5-medium\",\n",
    "    torch_dtype=torch.bfloat16,           \n",
    "    cache_dir=\"./models/huggingface\"\n",
    ").to(device)\n",
    "pipe.enable_attention_slicing()\n",
    "print(\"已启用注意力切片。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611b007-f8d5-4627-8a39-0b056267a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, os, torch, time\n",
    "from torch.amp import autocast\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 设置参数\n",
    "prompt = \"a photo of a bydxt Pavilion in the snow\"  # 根据您的需要调整提示词\n",
    "guidance_scale = 5\n",
    "num_inference_steps = 50\n",
    "height = 512\n",
    "width = 512\n",
    "num_images_total = 100  # 需要生成的图片总数\n",
    "\n",
    "# 创建FID数据集保存目录\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "fid_dataset_dir = os.path.join(output_dir, f\"fid_dataset_{timestamp}\")\n",
    "os.makedirs(fid_dataset_dir, exist_ok=True)\n",
    "\n",
    "print(f\"开始生成FID数据集，总计图片数: {num_images_total}，保存目录: {fid_dataset_dir}\")\n",
    "\n",
    "# 设置基本种子\n",
    "base_seed = 42\n",
    "images_generated = 0\n",
    "start_time = time.time()\n",
    "\n",
    "# 使用tqdm创建进度条\n",
    "progress_bar = tqdm(total=num_images_total, desc=\"生成FID数据集\")\n",
    "\n",
    "# 批量生成图片\n",
    "try:\n",
    "    while images_generated < num_images_total:\n",
    "        # 每次生成一张图片，使用不同种子\n",
    "        seed = base_seed + images_generated\n",
    "        generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
    "        \n",
    "        with autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "            image = pipe(\n",
    "                prompt=prompt,\n",
    "                guidance_scale=guidance_scale,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                height=height,\n",
    "                width=width,\n",
    "                generator=generator,\n",
    "            ).images[0]\n",
    "        \n",
    "        # 保存图片，使用序号命名\n",
    "        img_filename = f\"fid_image_{images_generated:04d}.png\"\n",
    "        img_path = os.path.join(fid_dataset_dir, img_filename)\n",
    "        image.save(img_path)\n",
    "        \n",
    "        # 更新计数和进度条\n",
    "        images_generated += 1\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "        # 显示进度和预计剩余时间\n",
    "        elapsed = time.time() - start_time\n",
    "        images_per_sec = images_generated / elapsed\n",
    "        remaining_time = (num_images_total - images_generated) / images_per_sec if images_per_sec > 0 else 0\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            \"速度\": f\"{images_per_sec:.2f}张/秒\",\n",
    "            \"剩余时间\": f\"{remaining_time/60:.1f}分钟\"\n",
    "        })\n",
    "        \n",
    "        # 每10张图片清理一次CUDA缓存，防止内存泄漏\n",
    "        if images_generated % 10 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\n生成过程被中断。已生成 {images_generated} 张图片。\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n生成过程出错: {str(e)}。已生成 {images_generated} 张图片。\")\n",
    "finally:\n",
    "    progress_bar.close()\n",
    "    \n",
    "    # 输出完成信息\n",
    "    total_time = time.time() - start_time\n",
    "    if images_generated > 0:\n",
    "        avg_time_per_image = total_time / images_generated\n",
    "        print(f\"FID数据集生成完成! 共 {images_generated} 张图片\")\n",
    "        print(f\"总用时: {total_time:.1f}秒 (平均 {avg_time_per_image:.2f}秒/张)\")\n",
    "    else:\n",
    "        print(f\"未能生成任何图片。总运行时间: {total_time:.1f}秒\")\n",
    "    print(f\"保存路径: {fid_dataset_dir}\")\n",
    "    \n",
    "    # 保存数据集信息\n",
    "    with open(os.path.join(fid_dataset_dir, \"dataset_info.txt\"), \"w\") as f:\n",
    "        f.write(f\"生成日期: {datetime.datetime.now()}\\n\")\n",
    "        f.write(f\"提示词: {prompt}\\n\")\n",
    "        f.write(f\"参数: guidance_scale={guidance_scale}, steps={num_inference_steps}\\n\")\n",
    "        f.write(f\"图片数量: {images_generated}\\n\")\n",
    "        f.write(f\"总生成时间: {total_time:.1f}秒\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40c39b-3349-4d18-b33d-f4d4e184c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#下载cifar\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# 1. 本地保存目录\n",
    "output_dir = \"./cifar10-train\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 2. 下载并加载 CIFAR-10 训练集\n",
    "ds = load_dataset(\"cifar10\", split=\"train\")\n",
    "\n",
    "# 3. 遍历并保存每张图像\n",
    "for idx, example in enumerate(ds):\n",
    "    # example[\"img\"] 是 PIL Image 对象也可能是 numpy array\n",
    "    img = example[\"img\"]\n",
    "    if not isinstance(img, Image.Image):\n",
    "        img = Image.fromarray(img)\n",
    "    # CIFAR-10 原始尺寸 32×32，无需调整\n",
    "    fname = f\"{idx:05d}.png\"\n",
    "    img.save(os.path.join(output_dir, fname))\n",
    "\n",
    "print(f\"共保存 {len(ds)} 张训练图像到 {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0120fe05-597b-437c-b624-96283ba49f97",
   "metadata": {},
   "source": [
    "计算FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95aeab19-41db-40d2-b7ea-1760a3a46617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute FID between two folders\n",
      "Found 100 images in the folder ./diff_attention/fid_raw_dataset_20250531_0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FID fid_raw_dataset_20250531_0042 : 100%|██████████| 4/4 [00:08<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 images in the folder cifar10-train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FID cifar10-train : 100%|██████████| 1563/1563 [00:55<00:00, 28.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID分数: 306.3826\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from cleanfid import fid\n",
    "os.environ['CLEANFID_CACHE'] = \"./fid_cache\"\n",
    "output_dir = \"./diff_attention\"\n",
    "# 创建目录路径\n",
    "fid_dataset_dir = os.path.join(output_dir, \"fid_raw_dataset_20250531_0042\")  # 您生成的图像路径\n",
    "reference_dataset = \"cifar10-train\"   # 使用预处理好的cifar10验证集 \"cifar10-train\"\n",
    "\n",
    "# 计算FID\n",
    "fid_score = fid.compute_fid(\n",
    "    fid_dataset_dir,  # 生成图像路径 \n",
    "    reference_dataset,  # 参考数据集\n",
    "    mode=\"clean\",  # 使用官方实现的标准化预处理\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    batch_size=32,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"FID分数: {fid_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f640b5-b821-4c9b-b4c5-c3459d329748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "from cleanfid import fid\n",
    "\n",
    "gen_dir = \"./dreambooth-sd35/fid_dataset_20250530_1824\"  # 你已经有的生成图\n",
    "ref_dir = \"./datasets/tju-pavilion-ref\"                         # 准备存放参考图\n",
    "\n",
    "os.makedirs(ref_dir, exist_ok=True)\n",
    "\n",
    "dataset_id = \"zjake/Memorial-Pavilion-of-TJU\"\n",
    "ds = load_dataset(dataset_id, split=\"train\", cache_dir=\"./datasets\")\n",
    "\n",
    "for idx, example in enumerate(ds):\n",
    "    img = example[\"image\"]\n",
    "    # 如果不是 PIL.Image，把它转成\n",
    "    if not isinstance(img, Image.Image):\n",
    "        img = Image.fromarray(img)\n",
    "    img = img.convert(\"RGB\")\n",
    "    # 保存成 PNG 或 JPEG\n",
    "    fname = f\"{idx:05d}.png\"\n",
    "    img.save(os.path.join(ref_dir, fname))\n",
    "\n",
    "print(f\"共导出 {len(ds)} 张参考图到 {ref_dir}\")\n",
    "\n",
    "\n",
    "os.environ['CLEANFID_CACHE'] = \"./fid_cache\"\n",
    "fid_score = fid.compute_fid(\n",
    "    gen_dir,            # 你的生成图文件夹\n",
    "    ref_dir,            # 你刚导出的参考图文件夹\n",
    "    mode=\"clean\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    batch_size=32,\n",
    "    verbose=True\n",
    ")\n",
    "print(f\"FID 分数: {fid_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adad3c8-a734-4f78-9162-c4231e4e110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#流式加载和保存\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "from cleanfid import fid\n",
    "\n",
    "# —— 配置参数 —— #\n",
    "style_name     = \"Impressionism\"                        # 要导出的风格\n",
    "limit          = 200                                     # 最多导出多少张参考图\n",
    "hf_dataset_id  = \"huggan/wikiart\"\n",
    "wikiart_folder = \"./datasets/wikiart-impressionism\"               # 本地保存参考图的目录\n",
    "gen_folder     = \"fid_dataset_LoRA_Impressionism20250530_2031\"  # 你的生成图目录\n",
    "\n",
    "os.makedirs(wikiart_folder, exist_ok=True)\n",
    "\n",
    "# —— 1. 找到 style 对应的索引 —— #\n",
    "# 我们先加载一次 non-streaming，以获取 features 元信息\n",
    "ds_info  = load_dataset(hf_dataset_id, split=\"train\", streaming=True, cache_dir=\"./hf_cache\")\n",
    "style_idx = ds_info.features[\"style\"].names.index(style_name)\n",
    "\n",
    "# —— 2. 流式遍历并按风格筛选导出 —— #\n",
    "ds_stream = load_dataset(hf_dataset_id, split=\"train\", streaming=True, cache_dir=\"./hf_cache\")\n",
    "count = 0\n",
    "for ex in ds_stream:\n",
    "    if ex[\"style\"] == style_idx:\n",
    "        img = ex[\"image\"]\n",
    "        if not isinstance(img, Image.Image):\n",
    "            img = Image.open(img).convert(\"RGB\")\n",
    "        fname = f\"{count:05d}.png\"\n",
    "        img.save(os.path.join(wikiart_folder, fname))\n",
    "        count += 1\n",
    "        if count >= limit:\n",
    "            break\n",
    "\n",
    "print(f\"已保存 {count} 张“{style_name}”风格的参考图到 {wikiart_folder}\")\n",
    "\n",
    "# —— 3. 计算 FID —— #\n",
    "os.environ['CLEANFID_CACHE'] = \"./fid_cache\"\n",
    "fid_score = fid.compute_fid(\n",
    "    gen_folder,       # 生成图目录\n",
    "    wikiart_folder,   # 参考图目录\n",
    "    mode=\"clean\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    batch_size=32,\n",
    "    verbose=True\n",
    ")\n",
    "print(f\"FID ({style_name}): {fid_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce4193a-7801-4005-b7af-05d51deff614",
   "metadata": {},
   "source": [
    "CLIP SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c522cfee-2b95-4cc1-ae6e-bac8c72ea0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 000  CLIPScore: 0.3128\n",
      "Image 001  CLIPScore: 0.3155\n",
      "Image 002  CLIPScore: 0.3162\n",
      "Image 003  CLIPScore: 0.2746\n",
      "Image 004  CLIPScore: 0.3092\n",
      "Image 005  CLIPScore: 0.3100\n",
      "Image 006  CLIPScore: 0.3203\n",
      "Image 007  CLIPScore: 0.3103\n",
      "Image 008  CLIPScore: 0.3042\n",
      "Image 009  CLIPScore: 0.3315\n",
      "Image 010  CLIPScore: 0.3284\n",
      "Image 011  CLIPScore: 0.3010\n",
      "Image 012  CLIPScore: 0.3175\n",
      "Image 013  CLIPScore: 0.2872\n",
      "Image 014  CLIPScore: 0.3243\n",
      "Image 015  CLIPScore: 0.2938\n",
      "Image 016  CLIPScore: 0.3304\n",
      "Image 017  CLIPScore: 0.3180\n",
      "Image 018  CLIPScore: 0.3190\n",
      "Image 019  CLIPScore: 0.3026\n",
      "Image 020  CLIPScore: 0.3180\n",
      "Image 021  CLIPScore: 0.3144\n",
      "Image 022  CLIPScore: 0.3036\n",
      "Image 023  CLIPScore: 0.2914\n",
      "Image 024  CLIPScore: 0.3338\n",
      "Image 025  CLIPScore: 0.3120\n",
      "Image 026  CLIPScore: 0.3119\n",
      "Image 027  CLIPScore: 0.3433\n",
      "Image 028  CLIPScore: 0.3196\n",
      "Image 029  CLIPScore: 0.3197\n",
      "Image 030  CLIPScore: 0.3065\n",
      "Image 031  CLIPScore: 0.2991\n",
      "Image 032  CLIPScore: 0.3345\n",
      "Image 033  CLIPScore: 0.3229\n",
      "Image 034  CLIPScore: 0.3211\n",
      "Image 035  CLIPScore: 0.3170\n",
      "Image 036  CLIPScore: 0.3169\n",
      "Image 037  CLIPScore: 0.3079\n",
      "Image 038  CLIPScore: 0.3401\n",
      "Image 039  CLIPScore: 0.2946\n",
      "Image 040  CLIPScore: 0.3012\n",
      "Image 041  CLIPScore: 0.3239\n",
      "Image 042  CLIPScore: 0.3041\n",
      "Image 043  CLIPScore: 0.2950\n",
      "Image 044  CLIPScore: 0.3236\n",
      "Image 045  CLIPScore: 0.3229\n",
      "Image 046  CLIPScore: 0.3246\n",
      "Image 047  CLIPScore: 0.3166\n",
      "Image 048  CLIPScore: 0.3146\n",
      "Image 049  CLIPScore: 0.3139\n",
      "Image 050  CLIPScore: 0.3102\n",
      "Image 051  CLIPScore: 0.3347\n",
      "Image 052  CLIPScore: 0.3263\n",
      "Image 053  CLIPScore: 0.3253\n",
      "Image 054  CLIPScore: 0.3175\n",
      "Image 055  CLIPScore: 0.3375\n",
      "Image 056  CLIPScore: 0.3304\n",
      "Image 057  CLIPScore: 0.3265\n",
      "Image 058  CLIPScore: 0.3263\n",
      "Image 059  CLIPScore: 0.3204\n",
      "Image 060  CLIPScore: 0.3262\n",
      "Image 061  CLIPScore: 0.2889\n",
      "Image 062  CLIPScore: 0.3041\n",
      "Image 063  CLIPScore: 0.3061\n",
      "Image 064  CLIPScore: 0.3118\n",
      "Image 065  CLIPScore: 0.3195\n",
      "Image 066  CLIPScore: 0.3251\n",
      "Image 067  CLIPScore: 0.3212\n",
      "Image 068  CLIPScore: 0.3285\n",
      "Image 069  CLIPScore: 0.3169\n",
      "Image 070  CLIPScore: 0.3352\n",
      "Image 071  CLIPScore: 0.3220\n",
      "Image 072  CLIPScore: 0.3233\n",
      "Image 073  CLIPScore: 0.3153\n",
      "Image 074  CLIPScore: 0.3176\n",
      "Image 075  CLIPScore: 0.2931\n",
      "Image 076  CLIPScore: 0.3023\n",
      "Image 077  CLIPScore: 0.2996\n",
      "Image 078  CLIPScore: 0.3207\n",
      "Image 079  CLIPScore: 0.3006\n",
      "Image 080  CLIPScore: 0.3080\n",
      "Image 081  CLIPScore: 0.3318\n",
      "Image 082  CLIPScore: 0.3297\n",
      "Image 083  CLIPScore: 0.2982\n",
      "Image 084  CLIPScore: 0.2888\n",
      "Image 085  CLIPScore: 0.2861\n",
      "Image 086  CLIPScore: 0.3239\n",
      "Image 087  CLIPScore: 0.3009\n",
      "Image 088  CLIPScore: 0.3049\n",
      "Image 089  CLIPScore: 0.3189\n",
      "Image 090  CLIPScore: 0.3160\n",
      "Image 091  CLIPScore: 0.3148\n",
      "Image 092  CLIPScore: 0.3085\n",
      "Image 093  CLIPScore: 0.2960\n",
      "Image 094  CLIPScore: 0.3208\n",
      "Image 095  CLIPScore: 0.3265\n",
      "Image 096  CLIPScore: 0.3179\n",
      "Image 097  CLIPScore: 0.3132\n",
      "Image 098  CLIPScore: 0.3331\n",
      "Image 099  CLIPScore: 0.3274\n",
      "\n",
      "平均 CLIPScore: 0.3149\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# —— 1. 配置 —— #\n",
    "image_dir = \"./diff_attention/fid_raw_dataset_20250531_0042\"\n",
    "# 请准备一个与图像一一对应的 prompt 列表，长度要与 image_list 相同\n",
    "prompt = [\n",
    "    \"a beautiful bottle on a wooden table\"\n",
    "]\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# —— 2. 加载 CLIP 模型与预处理器 —— #\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "model     = CLIPModel.from_pretrained(model_name,cache_dir=\"models/huggingface\").to(device).eval()\n",
    "processor = CLIPProcessor.from_pretrained(model_name,cache_dir=\"models/huggingface\")\n",
    "\n",
    "# —— 3. 扫描图像文件 —— #\n",
    "# 只读取常见图片后缀，可视需要扩展\n",
    "image_files = sorted([\n",
    "    os.path.join(image_dir, fn)\n",
    "    for fn in os.listdir(image_dir)\n",
    "    if fn.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "])\n",
    "\n",
    "prompts = prompt*len(image_files)\n",
    "assert len(image_files) == len(prompts), \"图像数量和 prompts 数量必须一致！\"\n",
    "\n",
    "# —— 4. 批量处理 —— #\n",
    "batch_size = 16  # 可根据显存调整\n",
    "all_scores = []\n",
    "\n",
    "for i in range(0, len(image_files), batch_size):\n",
    "    batch_imgs = [ Image.open(f).convert(\"RGB\") for f in image_files[i : i+batch_size] ]\n",
    "    batch_text = prompts[i : i+batch_size]\n",
    "\n",
    "    # 预处理并移动到设备\n",
    "    inputs = processor(text=batch_text,\n",
    "                       images=batch_imgs,\n",
    "                       return_tensors=\"pt\",\n",
    "                       padding=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs    = model(**inputs)\n",
    "        img_embeds = outputs.image_embeds    # (B, D)\n",
    "        txt_embeds = outputs.text_embeds     # (B, D)\n",
    "\n",
    "        # 归一化\n",
    "        img_embeds = img_embeds / img_embeds.norm(dim=-1, keepdim=True)\n",
    "        txt_embeds = txt_embeds / txt_embeds.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # 计算逐对余弦相似度\n",
    "        scores = (img_embeds * txt_embeds).sum(dim=-1)  # (B,)\n",
    "        all_scores.append(scores.cpu())\n",
    "\n",
    "# —— 5. 汇总并输出 —— #\n",
    "all_scores = torch.cat(all_scores, dim=0).numpy()\n",
    "for idx, score in enumerate(all_scores):\n",
    "    print(f\"Image {idx:03d}  CLIPScore: {score:.4f}\")\n",
    "\n",
    "print(f\"\\n平均 CLIPScore: {all_scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b18d62-308d-4430-8fb1-cda778ce6ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d388653c-8376-4135-b89d-1a4795dfeb45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab56904-5968-4509-9152-6df77a8ca917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71128e49-5931-4cc4-909b-04c0d5335424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e236a-f850-42da-b112-0bc036d88718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zihaopytorch",
   "language": "python",
   "name": "zihaopytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
